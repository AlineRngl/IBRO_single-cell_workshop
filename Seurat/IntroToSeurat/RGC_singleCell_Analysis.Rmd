---
title: "IBRO"
output: html_document
date: "2023-05-21"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Single-cell RNA-seq data analysis using **Seurat**
In this section we will learn to:

1. Read count matrices  
2. Data pre-processing  
    + Perform quality control
    + Normalize data to log  
    + Identification of highly variable features (gene selection)  
3. Group data into cell types  
    + Data scaling  
    + Principal Component Analysis (PCA) 
    + Clustering  
    + UMAP visualization  
4. Find differential expressed genes (cluster biomarkers)  
5. Visualize expression data  
    + Violin plot  
    + Color UMAP by gene expression  
    + Dot plot  
5. Subsample data  
6. Use TPM matrices in a Seurat object  

### Load libraries
First, we load all the libraries we need. Libraries are packages of functions we can install but need to be loaded every time we restart R
```{r, message=FALSE, results='hide', warning=FALSE}
library(dplyr)
library(Seurat)
library(patchwork)
library(data.table)
library(ggplot2)
```

## Data pre-processing 
### Load RGC data from Tran et al. 2019
Load counts and save them in R format
```{r, eval= F, echo=T}
# Load the RGC dataset
counts <- t(read.table('C:/Users/gisel/Documents/McGill/Summer2023/IBRO2023/Seurat/AdultRGCs/GSE133382_AtlasRGCs_CountMatrix.csv',sep = ',', header = TRUE, row.names = 1))

# Save data set in R format to read faster next time
save.image("C:/Users/gisel/Documents/McGill/Summer2023/IBRO2023/Seurat/AdultRGCs/Atlascounts.RData")
```

```{r, eval=FALSE}
# Here only a subset of the data is selected so the tutorial can run faster in my laptop
# Keep 5000 genes plus genes of interest
# Keep the first 10000 cells
genes2keep <- c(setdiff( which(colnames(counts) %in% c("Rbfox3", "Gfap", "Rbpms", "Slc17a6", "Slc32a1","Vsx2","Arr3","Slc1a3","Cdh1",  "Cdh2",  "Cdh3",  "Cdh4" , "Cdh6",  "Cdh7",  "Cdh8",  "Cdh9",  "Cdh10", "Cdh11", "Cdh12", "Cdh13", "Cdh15", "Cdh18", "Cdh20","Cdh22", "Cdh23", "Cdh24" )), 1:5000), c(1:5000))
counts <- counts [1:10000, genes2keep]
save.image("W:/IBRO2023/Seurat/AdultRGCs/Atlascounts_subset.RData")

```


Load counts and convert it in Seurat format.  
The input matrix must have genes in the rows, cells in the columns.
```{r, warning=FALSE}
# Load data set in R format
# load("F:/Documents/AjunrGrant2021/RGC/Atlascounts.RData") # full version
load("W:/IBRO2023/Seurat/AdultRGCs/Atlascounts_subset.RData")
# Initialize the Seurat object with raw counts(non-normalized data).
# unnormalized data with cells as columns and features (genes) as rows

CountsAtlas <- CreateSeuratObject(counts = t(counts), project = "RGCAtlas")
CountsAtlas

```

Take a look at the data for a few genes and 10 cells
```{r}
t(counts[1:10, c("Cdh4", "Cdh13", "Cdh7")])
rm(counts)
```


To load 10x Data: Directory containing the matrix.mtx, genes.tsv (or features.tsv), and barcodes.tsv files provided by 10X
```{r, eval=F, echo=T}
counts <- Read10X(data.dir = "DataDirectory") # replace "DataDirectory" with your own path
```

#### set seed so our result are reproducible
```{r}
set.seed(0)
```

### Perform quality control
Visualize QC metrics as a violin plot
```{r, fig.width=9}
QCviolin <- VlnPlot(object = CountsAtlas, features = c("nFeature_RNA", "nCount_RNA"), ncol = 2)
QCviolin
```

*FeatureScatter* is typically used to visualize feature-feature relationships
```{r}
plot2 <- FeatureScatter(object = CountsAtlas, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
plot2
```

Select cells where a minimum of 1200 genes were detected and not more than 7500. Cells with few genes are bad quality while cells with many genes could be doublets.
```{r}
# CountsAtlas <- subset(x= CountsAtlas, subset = nFeature_RNA > 2000 & nFeature_RNA < 7500)
CountsAtlas <- subset(CountsAtlas, subset = nFeature_RNA > 200 & nFeature_RNA < 1100)
```

### Normalize data
Normalize the gene expression measurements for each cell by the total expression
```{r}
CountsAtlas <- NormalizeData(object = CountsAtlas, normalization.method = "LogNormalize", scale.factor = 10000)
```

## Identification of highly variable features (gene selection)
```{r, warning=FALSE}
CountsAtlas <- FindVariableFeatures(object = CountsAtlas, selection.method = "vst", nfeatures =2000)

# Identify the 10 most highly variable genes
top10 <- head(VariableFeatures(object = CountsAtlas), 10)

# plot variable features with labels
plot1 <- VariableFeaturePlot(CountsAtlas)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot1 
plot2
```

## Grouping "cell types" in dataset

### Scaling data: 

Scaling is a necessary standard pre-processing for downstream analysis that use dimensional reduction techniques like principal component analysis (PCA). 

This step is important because allows us to consider genes with a lot and few counts equally, while focusing more in their variability. In this way, highly-expressed genes do not dominate. For this, *ScaleData*:  

* Shifts the expression of each gene, so that the mean expression across cells is 0,
* Scales the expression of each gene, so that the variance across cells is 1.
```{r, eval=F, warning=FALSE}
#For all genes
all.genes <- rownames(CountsAtlas)
CountsAtlas <- ScaleData(object = CountsAtlas, features = all.genes) #takes < 10min to run if using all counts and genes
```

If *features* is not specified, only the top 2000 genes are used. In this example only 2000 (default) will be use for clustering given the computer power available but results usually remain pretty similar to those of "all.genes".

```{r}
CountsAtlas <- ScaleData(object = CountsAtlas) #takes ~10min to run
```

### Linear dimension reduction
The amount of data we have is huge **(42750 cells and 27933 genes!!!)** if using the whole dataset. So we need to make it smaller but at the same time conserve the important information. For this we can use PCA, which is a mathematical method that takes huge amounts of data and keeps only the information that accounts for the majority of the variability in the data.

```{r}
# Here we use the previously 2000 variable genes we selected above
CountsAtlas <- RunPCA(object = CountsAtlas, features =  VariableFeatures(object = CountsAtlas), npcs = 100) # take a few minutes to run
```

#### Determine the ‘dimensionality’ of the dataset
PCA will return a matrix of the same dimension as input matrix. However, this PCA matrix contains *"eigenvalues"* which represent the weight of each gene in each PC (eigenvector). PCA accumulates the major information variability in the top PCs and almost none in the bottom ones. Therefore, we want to only select a few of the top PCs that more robustly represent a compression of our dataset. **But exactly how many?**

Selecting the right amount of PCs is challenging and a little arbitrary.You could try using many methods found in the Seurat website, but for now here is an heuristic method that gives a good approximate without using a lot of computational power.

Here, we plot the standard deviation of the PCs to identify the "elbow", which corresponds with the significant dimension in the PC that contains the relevant information of our data.

We can observe an ‘elbow’ around PC50-65, suggesting that the majority of true signal is captured in the first 60 PCs.

```{r}
# Here we select only the first 100 PCs to be displayed
ElbowPlot(object = CountsAtlas, ndims = 100)
```

Once we selected our PCs, we can go ahead and use them to cluster cells into different groups based on expression.

Although the math behind the clustering methods is complex, we just need to understand that based on how similar cells are they are pulled together while dissimilarities push them away.

*FindNeighbors* finds the distance between cells while *FindClusters* groups cells based on these distances.

### Clustering
In this first clustering I want to identified if in the dataset I have cell types other than RGC so I use a low resolution. Values > 1 are high resolution and <1 are low resolution, but it needs to be setup based on the data we are looking at. 
```{r}
CountsAtlas <- FindNeighbors(object = CountsAtlas, dims = 1:60) # 60 PCs are used
CountsAtlas <- FindClusters(object = CountsAtlas, resolution = 0.2)
```

This clustering method finds 51 groups if using the whole dataset and 14 if using a subset

#### Run non-linear dimensional reduction (UMAP)
After we have our clusters we can use a visualization method to explore our datasets in a 2-D space. 

Here is recommended to use the same numbers of PCs we used for our clustering
```{r , warning=FALSE}
CountsAtlas <- RunUMAP(object = CountsAtlas, dims = 1:60)
UMAPplot <- DimPlot(object = CountsAtlas, reduction = "umap",  label = TRUE)
UMAPplot

```


Once we are done with this part of the analysis you can save this pre-processed data in R format so you don't have to run it again.
```{r}
save.image("W:/IBRO2023/PreprocessedDataRGCs.RData")
```

Or only save the Seurat object
```{r, eval=FALSE}
saveRDS(object = CountsAtlas, file = "W:/IBRO2023/CountsAtlasW:/IBRO2023/CountsAtlas.rds")
```


To reload your data you can simply read the file you saved (image or object). **Note that libraries need to be re-load if you closed R**
```{r}
load("W:/IBRO2023/PreprocessedDataRGCs.RData")
#readRDS("W:/IBRO2023/CountsAtlas.rds")
```


## Finding differentially expressed features (cluster biomarkers)
Seurat can help us identified markers that define our cluster based on differential expression. For this, we can use positive and negative markers. 

Let's start with finding markers in cluster 1 and look at the top 5 markers   

*ident.1* defines the cluster you want to find marker for

```{r}
cluster2.markers <- FindMarkers(CountsAtlas, ident.1 = 1, min.pct = 0.25) # ~9 min to run
head(cluster2.markers, n = 5) # top 5 markers

```

We can also compare one cluster vs any other numbers of clusters. For example cluster 4 vs cluster 1 and 3

```{r}
cluster4.markers <- FindMarkers(object = CountsAtlas, ident.1 = 4, ident.2 = c(1, 3), min.pct = 0.25)
head(cluster4.markers, n = 5)
```

To find positive makers for every cluster in which the log fold change is at least 2. 

```{r, results = "hide"}
CountsAtlas.markers <- FindAllMarkers(object = CountsAtlas, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 2) # take ~15min to run
CountsAtlas.markers %>%
    group_by(cluster) %>%
    slice_max(n = 2, order_by = avg_log2FC)
```
Here, some clusters did not showed unique markers, while others have many.

To look into a subset of genes and see if this are DE we can give Seurat a list with these genes. Here I'm loading a list of genes from a text file containing Cadherin genes
```{r, results = "hide"}
cdhs<-  read.table("F:/Documents/Drop-seq-Sanes/AjunGrant/Cdhs", stringsAsFactors = FALSE)$V1
markersCdhs <- FindAllMarkers(object =CountsAtlas, features = cdhs, only.pos= T,logfc.threshold = .2)
```

```{r}
cdhs
markersCdhs
```


### Visualizing data
#### Look at specific genes across clusters   

**Violin plot**
Here we can compare the distribution of markers across cells in each cluster.    
We can find neurons using *Rbfox3* gene and glia using *Gfap* gene. This data doesn't contain glia cells.
```{r, fig.width=9}
VlnPlot(object = CountsAtlas, features = c("Rbfox3", "Gfap"))
```

**UMAP**   
Another way to look at the whole data while looking at genes expression is by coloring our UMAP based on genes expression. 
```{r, fig.width=9}
FeaturePlot(object = CountsAtlas, features = c("Rbfox3", "Gfap"))
```

We can also look at both features at the same time
```{r fig.width=9}
FeaturePlot(CountsAtlas, features = c("Rbfox3", "Gfap"), blend = TRUE)

```


#### Search for cell types   

Here, we take a look at RGC (Rbpms, Slc17a6), amacrine (Slc32a1), bipolar(Vsx2) and photoreceptor (Arr3) cell markers. We only have RGCs and ACs in this dataset.

```{r, fig.width=9, fig.height=15}
celltypeMarkers <- c("Rbpms", "Slc17a6", "Slc32a1","Vsx2","Arr3","Slc1a3") #Save genes names in a variable
FeaturePlot(object = CountsAtlas, features = celltypeMarkers)
```

**DotPlot**    

*DotPlot* to look at the expression of many genes and the amount of cells following that expression pattern inside the cluster.
```{r,fig.width=9}
DotPlot(object = CountsAtlas, features = celltypeMarkers) + RotatedAxis() + coord_flip()
```

**Gene average expression per cluster**       
We can also calculate the average expression for our genes of interest
```{r}
AverageExpMarkers <- AverageExpression(object = CountsAtlas, features = celltypeMarkers)
AverageExpMarkers
```

Once we found the clusters that contain the cells we don't want (in this case ACs), we subset our dataset and keep only the clusters we are interested on (RGCs). This remove cluster 3,20 and 29 because expression is > 1 if using the whole dataset.
```{r, fig.width=9}
cells_to_remove <- WhichCells(object = CountsAtlas, idents = which(AverageExpMarkers$RNA["Slc32a1",] > 1)-1)
CountsAtlas_RGCs <- subset(CountsAtlas, cells = setdiff(Cells(CountsAtlas), cells_to_remove))

dim(CountsAtlas)
dim(CountsAtlas_RGCs)
UMAPplot + theme(legend.position = "none")
DimPlot(object = CountsAtlas_RGCs, reduction = "umap") + theme(legend.position = "none")
FeaturePlot(object = CountsAtlas_RGCs, features = c("Slc17a6", "Slc32a1"))
```

Now we can re-cluster our data and look for RGC cells types if we wanted to. But given the resolution we stated in our clustering and that we did not remove many clusters we can keep using the same analysis we already have.

This is how we would re-run PCA, clustering and UMAP 
```{r, eval=F,}
CountsAtlas_RGCs <- FindVariableFeatures(object = CountsAtlas_RGCs, selection.method = "vst", nfeatures =2000)
CountsAtlas_RGCs <- ScaleData(object = CountsAtlas_RGCs) #takes ~10min to run
ElbowPlot(object = CountsAtlas_RGCs, ndims = 100)
CountsAtlas_RGCs <- FindNeighbors(object = CountsAtlas_RGCs, dims = 1:60) # 60 PCs are used
CountsAtlas_RGCs <- RunUMAP(object = CountsAtlas_RGCs, dims = 1:60)
DimPlot(object = CountsAtlas_RGCs, reduction = "umap")
```

Save data again
```{r}
save.image("W:/IBRO2023/PreprocessedDataRGCs_2.RData")

```


# TPM matrices
When downloading databases, sometimes we can also obtain data normalized by transcript per million (TPM). This data does not allow direct differential analysis (DE) like raw counts but it is good to visualize data and get a sense of the gene expression in our data set. In this example, we will use the same data than above (Tran et al., 2019) but download from the Broad Institute which comes as TPMs.   


Load TPMs   
In this case the format of our data is a R file. You can load the data by simply using the *load* function. This file contains:   

* *ExpMat*: a matrix with genes in rows and cells in column.   
* *cell_types*: a factor vector with the the classification for each cell.   

```{r}
rm() # remove all variables from directory
gc() # free unused memory
load("F:/Documents/Drop-seq-Sanes/Tran_RGC_atlas_data.Rdata")
TPM_Atlas <- CreateSeuratObject(counts = ExpMat, project = "RGCAtlas") #Load TPM to a Seurat object

ExpMat[1:10, 1:10]
cell_type[1:5]
levels(cell_type)
```

Since the file already has the cell type for each cell, it is not necessary to create our own cluster and we can look at the interesting features of the gene of interest. 
```{r}
# Add cell type to my Seurat object
Idents(object = TPM_Atlas) <- cell_type
```

Let's say we want to take a look at the expression of a gene across all cell types. For example *Cdh4*
```{r, fig.width=9}
VlnPlot(object = TPM_Atlas, features = c("Cdh4")) 

```

We can customize the appearance of our plots
```{r, , fig.width=9}
VlnPlot(object = TPM_Atlas, features = c("Cdh4"), cols = rep("gray", length(levels(Idents(object = TPM_Atlas)))), sort = 'increasing', pt.size = 0 )  + theme(legend.position = "none", axis.text = element_text(size = 10)) 

```
 
Dot plots can be plotted too.

```{r, fig.width=9}
DotPlot(object = TPM_Atlas, features = c("Cdh4", "Cdh13", "Cdh7", "Cdh12"),  cols = c("blue", "red")) + theme(text = element_text(size = 10), axis.text = element_text(size = 8) )  +  RotatedAxis() + coord_flip()

```

We can also find markers specific for our cluster but it is better to use counts than TPMs. Here we want to find specific markers for FminiOFF when looking at all F-RGCs which at least have a 2 fold difference.

```{r}
markersF <- FindMarkers(object = TPM_Atlas, ident.1 = "3_FminiON", ident.2  = c("4_FminiOFF", "28_FmidiOFF","38_FmidiON"), logfc.threshold = 2 )
markersF
```

Then we can take a look at the expression of these markers using dotplot, We only got 4:
```{r}
DotPlot(object = TPM_Atlas, features = rownames(markersF),idents = c("3_FminiON",  "4_FminiOFF", "28_FmidiOFF","38_FmidiON")  , cols = c("blue", "red")) + theme(text = element_text(size = 10), axis.text = element_text(size = 8) )  +  RotatedAxis() + coord_flip()
```

Using this information you could find combination of markers that label specific cell types. 





